{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9329ecb4-e59b-43dd-9e28-f11e046b7770",
   "metadata": {},
   "source": [
    "# BM25 benchmark\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "543dd41e-3154-41e7-b47e-1a17b8726ad0",
   "metadata": {},
   "source": [
    "The BM25 algorithm was first introduced in the paper https://www.researchgate.net/publication/221037764_Okapi_at_TREC-3 where presented a new ranking approach, that improved the existing versions  and the TF-IDF. \n",
    "\n",
    "The BM25 model addresses two key limitations of the TF-IDF model, which was widely used at the time. These limitations are:\n",
    "\n",
    "1. **Term Saturation**: In the TF-IDF model, term frequency (TF) has diminishing returns, meaning that additional occurrences of a term in a document yield diminishing benefits. The BM25 model introduces a saturation function to address this issue.\n",
    "\n",
    "2. **Document Length Normalization**: The TF-IDF model does not account for variations in document lengths. BM25 incorporates document length normalization, which helps in ranking shorter and longer documents more fairly.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d68fd5f-9b30-4b20-929f-050a43341aa2",
   "metadata": {},
   "source": [
    "BM25(D, Q) = âˆ‘ (IDF(q) * (f(q, D) * (k1 + 1)) / (f(q, D) + k1 * (1 - b + b * |D| / avgdl)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee7f5691-2731-4d36-bbfa-a095743f55bc",
   "metadata": {},
   "source": [
    "# How to evaluate recommender systems"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "102d1e55-ebe4-4a7c-a478-e15ae8184ad4",
   "metadata": {},
   "source": [
    "Evaluating recommender systems can involve different methods and metrics depending on the problem. Bellow a summary of the metrics that can be used. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf45bd12-b3a4-4b06-b032-56ab1d38bf1f",
   "metadata": {},
   "source": [
    "1. **Accuracy Metrics**: These measure how accurately the recommender system predicts user preferences.\n",
    "   - **Mean Absolute Error (MAE)** and **Root Mean Square Error (RMSE)**: These are statistical measures that calculate the average magnitude of errors in a set of predictions.\n",
    "   - **Precision and Recall**: Precision measures the proportion of recommended items that are relevant, while recall measures the proportion of relevant items that are recommended.\n",
    "   - **Top-N Accuracy**: This measures how often the top N recommendations include items that users actually interact with.\n",
    "\n",
    "2. **Diversity and Novelty Metrics**: These measure how varied and new the recommendations are.\n",
    "   - **Diversity**: Assesses how different the recommended items are from each other.\n",
    "   - **Novelty**: Measures how many new or unknown items are recommended to users.\n",
    "\n",
    "3. **Coverage Metrics**: These assess the breadth of the recommender system.\n",
    "   - **Catalog Coverage**: Measures the percentage of items in the catalog that are ever recommended.\n",
    "   - **User Coverage**: Measures the percentage of users for whom the system can generate recommendations.\n",
    "\n",
    "4. **Utility-Based Metrics**: These consider the usefulness of recommendations from a user's perspective.\n",
    "   - **Click-Through Rate (CTR)**: Measures how often users click on the recommended items.\n",
    "   - **Conversion Rate**: Measures how often recommendations lead to a sale or another desired action.\n",
    "\n",
    "5. **User Satisfaction Metrics**: Evaluates user experience and satisfaction with the recommendations.\n",
    "   - **User Surveys**: Direct feedback from users about their satisfaction with the recommendations.\n",
    "   - **Session Duration**: Longer sessions might indicate greater engagement with the recommendations.\n",
    "\n",
    "6. **Serendipity and Surprise Metrics**: These assess the unexpectedness of the recommendations.\n",
    "   - **Serendipity**: Measures how the system can recommend items that a user might not find on their own but ends up liking.\n",
    "   - **Surprise**: Measures how unexpected the recommendations are to the user.\n",
    "\n",
    "7. **Fairness and Bias Metrics**: These ensure that the recommendations are fair and unbiased.\n",
    "   - **Group Fairness**: Ensures that recommendations are equally effective for different user groups.\n",
    "   - **Item Exposure**: Ensures a fair distribution of exposure among items.\n",
    "\n",
    "8. **A/B Testing**: This involves comparing two or more versions of the recommender system to see which performs better according to specific metrics.\n",
    "\n",
    "9. **Online and Offline Evaluation**: \n",
    "   - **Offline Evaluation**: Uses historical data to evaluate the recommender system without impacting real users.\n",
    "   - **Online Evaluation**: Involves real-time testing with actual users, often through A/B testing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6596b104-f220-4b10-b1b5-560ff71216ac",
   "metadata": {},
   "source": [
    "# Is it possible to avoid full reconstruction of the bm25 index after a new item is added? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b08de117-d4db-4ac4-a1d1-3277ed2407d6",
   "metadata": {},
   "source": [
    "BM25, a ranking function used in information retrieval, is often implemented in search engines or document retrieval systems. When a new document or item is added to the collection, it traditionally requires reindexing to update the BM25 index to accurately reflect the new state of the document collection. This is because BM25 calculations are based on document frequency (DF) values for each term, which change with the addition of new documents.\n",
    "\n",
    "However, there are strategies to mitigate the need for full reconstruction of the BM25 index:\n",
    "\n",
    "1. **Incremental Indexing**: Instead of rebuilding the entire index, you can add the new document to the existing index and update the necessary statistics. This method requires careful management of term frequencies and document frequencies to ensure the index remains accurate.\n",
    "\n",
    "2. **Partitioned Indexes**: By partitioning the index, you can limit updates to a smaller portion of the index where the new document fits. This approach often involves creating a smaller, secondary index for new documents and merging it with the main index at regular intervals.\n",
    "\n",
    "3. **Deferred Updates**: In this approach, changes are collected over a period and then applied in bulk. This can be efficient if the rate of change is not too high, as it reduces the frequency of reindexing.\n",
    "\n",
    "4. **Using a Database with Real-time Indexing Capabilities**: Some modern databases and search engines are designed to handle real-time indexing efficiently. They automatically update the index as new data comes in, without requiring a full rebuild.\n",
    "\n",
    "5. **Near Real-time (NRT) Indexing**: This is a common approach in systems like Elasticsearch, where the index is updated almost in real time. It allows new documents to be searchable very quickly after being added, without the need for a full index rebuild.\n",
    "\n",
    "6. **Sharding**: In large-scale systems, sharding the index (dividing it into smaller, manageable pieces) can help. When a new document is added, only the relevant shard is updated, which is less resource-intensive than reindexing everything.\n",
    "\n",
    "Each of these strategies has its own trade-offs in terms of complexity, resource usage, and update latency. The choice depends on the specific requirements of the system, such as the rate of new document additions, the size of the document collection, and the acceptable latency for the documents to be searchable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8f196740-c9de-4415-852a-322f36b72be0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 2.0964289377349874), (1, 0), (2, 0)]\n"
     ]
    }
   ],
   "source": [
    "# Example\n",
    "import math\n",
    "from collections import defaultdict\n",
    "\n",
    "class IncrementalBM25Index:\n",
    "    def __init__(self):\n",
    "        self.documents = []\n",
    "        self.doc_freqs = defaultdict(int)\n",
    "        self.total_docs = 0\n",
    "        self.average_doc_len = 0\n",
    "\n",
    "    def add_document(self, document):\n",
    "        # Tokenize the document\n",
    "        tokens = document.split()\n",
    "\n",
    "        # Update document list\n",
    "        self.documents.append(tokens)\n",
    "        self.total_docs += 1\n",
    "\n",
    "        # Update document frequencies\n",
    "        unique_tokens = set(tokens)\n",
    "        for token in unique_tokens:\n",
    "            self.doc_freqs[token] += 1\n",
    "\n",
    "        # Update average document length\n",
    "        total_len = sum(len(doc) for doc in self.documents)\n",
    "        self.average_doc_len = total_len / self.total_docs\n",
    "\n",
    "    def compute_bm25(self, query, k1=1.5, b=0.75):\n",
    "        query_tokens = query.split()\n",
    "        scores = []\n",
    "\n",
    "        for index, doc in enumerate(self.documents):\n",
    "            score = 0\n",
    "            doc_len = len(doc)\n",
    "\n",
    "            for term in query_tokens:\n",
    "                if term in doc:\n",
    "                    tf = doc.count(term)\n",
    "                    df = self.doc_freqs[term]\n",
    "                    idf = math.log((self.total_docs - df + 0.5) / (df + 0.5) + 1)\n",
    "                    score += idf * (tf * (k1 + 1)) / (tf + k1 * (1 - b + b * doc_len / self.average_doc_len))\n",
    "\n",
    "            scores.append((index, score))\n",
    "\n",
    "        return sorted(scores, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Example usage\n",
    "index = IncrementalBM25Index()\n",
    "index.add_document(\"the quick brown fox\")\n",
    "index.add_document(\"jumps over the lazy dog\")\n",
    "index.add_document(\"new document added to index\")\n",
    "\n",
    "# Querying\n",
    "query = \"quick fox\"\n",
    "results = index.compute_bm25(query)\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "535144c5-573b-4912-9567-5249bd43cf68",
   "metadata": {},
   "source": [
    "# Existing benchmarks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82298286-4808-41ae-bb39-61a6d7129b41",
   "metadata": {},
   "source": [
    "In order to better compare internal models with existing ones the usage of public benchmarks is a common approach. Two of the most popular are: Beir and mteb. Bellow a summary of the two."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af393c79-7ce8-4445-878d-946daadfd95a",
   "metadata": {},
   "source": [
    "### BEIR (Benchmarking IR)\n",
    "\n",
    "BEIR, or Benchmarking IR, is a benchmark suite designed for evaluating Information Retrieval (IR) models, particularly in the context of neural retrieval. It's significant because it provides a comprehensive, diverse, and challenging set of datasets for testing the generalizability of these models. Key aspects of BEIR include:\n",
    "\n",
    "1. **Diverse Domains**: BEIR covers a wide range of domains, such as scientific articles, news articles, and general queries. This diversity ensures that models are tested in various scenarios, reflecting real-world applications.\n",
    "\n",
    "2. **Heterogeneous Tasks**: The benchmark includes different types of IR tasks like fact-checking, question answering, and citation prediction. This helps in understanding how well models perform across different IR challenges.\n",
    "\n",
    "3. **Zero-Shot Setting**: BEIR focuses on evaluating models in a zero-shot setting, where models are tested on datasets they were not trained on. This tests the model's ability to generalize to new data.\n",
    "\n",
    "4. **Comprehensive Evaluation Metrics**: BEIR employs standard IR metrics like Normalized Discounted Cumulative Gain (nDCG), Mean Reciprocal Rank (MRR), and Precision@k. These metrics give a well-rounded assessment of model performance.\n",
    "\n",
    "5. **Open and Extensible**: Researchers can contribute new datasets to BEIR, making it a growing and evolving benchmark.\n",
    "\n",
    "### MTEB (Multi-Task Evaluation Benchmark)\n",
    "\n",
    "MTEB, or the Multi-Task Evaluation Benchmark, is designed for evaluating large language models across a wide array of natural language processing (NLP) tasks. It's crucial for understanding how well these models can handle different types of language-related challenges. Key aspects of MTEB include:\n",
    "\n",
    "1. **Broad Task Coverage**: MTEB covers a wide range of NLP tasks, such as text classification, question answering, and text generation. This helps in assessing the versatility of language models.\n",
    "\n",
    "2. **Multi-Task Focus**: Unlike benchmarks that focus on a single task, MTEB evaluates models across multiple tasks simultaneously. This reflects real-world scenarios where models often need to handle various types of language processing tasks.\n",
    "\n",
    "3. **Benchmark for Large Models**: MTEB is particularly suited for evaluating large-scale language models, like GPT and BERT variants, providing insights into their strengths and weaknesses across tasks.\n",
    "\n",
    "4. **Quantitative Evaluation**: The benchmark uses a range of metrics specific to each task, providing a quantitative measure of performance.\n",
    "\n",
    "5. **Comparison Across Models**: MTEB allows for direct comparison between different language models, facilitating an understanding of which models perform best on specific types of tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d47f5c-2a69-4dae-ab7b-8e6b96c33ef1",
   "metadata": {},
   "source": [
    "# Let's experiment with BEIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91f4dacf-30ee-4629-8580-d9783734abd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load ms_marco using the hugging face lib\n",
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"ms_marco\", 'v1.1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8fc027d4-cba4-42f5-b01e-84f6daf6f722",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    validation: Dataset({\n",
       "        features: ['answers', 'passages', 'query', 'query_id', 'query_type', 'wellFormedAnswers'],\n",
       "        num_rows: 10047\n",
       "    })\n",
       "    train: Dataset({\n",
       "        features: ['answers', 'passages', 'query', 'query_id', 'query_type', 'wellFormedAnswers'],\n",
       "        num_rows: 82326\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['answers', 'passages', 'query', 'query_id', 'query_type', 'wellFormedAnswers'],\n",
       "        num_rows: 9650\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ffda4517-8c41-417e-bcb0-c8599add1604",
   "metadata": {},
   "outputs": [],
   "source": [
    "# organize datasets\n",
    "import pandas as pd\n",
    "\n",
    "train_df = pd.DataFrame(dataset[\"train\"])\n",
    "test_df = pd.DataFrame(dataset[\"test\"])\n",
    "validation_df = pd.DataFrame(dataset[\"validation\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7cf8b634-05d4-4071-b88b-638bc2a9d0a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>answers</th>\n",
       "      <th>passages</th>\n",
       "      <th>query</th>\n",
       "      <th>query_id</th>\n",
       "      <th>query_type</th>\n",
       "      <th>wellFormedAnswers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[Results-Based Accountability is a disciplined...</td>\n",
       "      <td>{'is_selected': [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]...</td>\n",
       "      <td>what is rba</td>\n",
       "      <td>19699</td>\n",
       "      <td>description</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[Yes]</td>\n",
       "      <td>{'is_selected': [0, 1, 0, 0, 0, 0, 0], 'passag...</td>\n",
       "      <td>was ronald reagan a democrat</td>\n",
       "      <td>19700</td>\n",
       "      <td>description</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[20-25 minutes]</td>\n",
       "      <td>{'is_selected': [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]...</td>\n",
       "      <td>how long do you need for sydney and surroundin...</td>\n",
       "      <td>19701</td>\n",
       "      <td>numeric</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[$11 to $22 per square foot]</td>\n",
       "      <td>{'is_selected': [0, 0, 0, 0, 0, 0, 0, 0, 1], '...</td>\n",
       "      <td>price to install tile in shower</td>\n",
       "      <td>19702</td>\n",
       "      <td>numeric</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[Due to symptoms in the body]</td>\n",
       "      <td>{'is_selected': [0, 0, 1, 0, 0, 0, 0, 0], 'pas...</td>\n",
       "      <td>why conversion observed in body</td>\n",
       "      <td>19703</td>\n",
       "      <td>description</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82321</th>\n",
       "      <td>[The act or action of propagating as a increas...</td>\n",
       "      <td>{'is_selected': [1, 0, 0], 'passage_text': ['d...</td>\n",
       "      <td>meaning of propagation</td>\n",
       "      <td>102124</td>\n",
       "      <td>description</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82322</th>\n",
       "      <td>[Yes]</td>\n",
       "      <td>{'is_selected': [0, 0, 1, 0, 0, 0, 0, 0, 0], '...</td>\n",
       "      <td>do you have to do a phd to be a clinical psych...</td>\n",
       "      <td>102125</td>\n",
       "      <td>description</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82323</th>\n",
       "      <td>[Chablis]</td>\n",
       "      <td>{'is_selected': [0, 1, 0, 0, 0, 0], 'passage_t...</td>\n",
       "      <td>what wine goes with oysters</td>\n",
       "      <td>102126</td>\n",
       "      <td>entity</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82324</th>\n",
       "      <td>[1 Lithium carbonate 150 mg capsules. Lithium ...</td>\n",
       "      <td>{'is_selected': [0, 0, 0, 1, 0, 0, 0, 0, 0], '...</td>\n",
       "      <td>what strengths does lithium come in</td>\n",
       "      <td>102127</td>\n",
       "      <td>description</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82325</th>\n",
       "      <td>[Burdick &amp; Jackson solvents are arranged in or...</td>\n",
       "      <td>{'is_selected': [1, 0, 0, 0, 0, 0, 0, 0, 0, 0]...</td>\n",
       "      <td>what is polarity index definition</td>\n",
       "      <td>102128</td>\n",
       "      <td>description</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>82326 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 answers  \\\n",
       "0      [Results-Based Accountability is a disciplined...   \n",
       "1                                                  [Yes]   \n",
       "2                                        [20-25 minutes]   \n",
       "3                           [$11 to $22 per square foot]   \n",
       "4                          [Due to symptoms in the body]   \n",
       "...                                                  ...   \n",
       "82321  [The act or action of propagating as a increas...   \n",
       "82322                                              [Yes]   \n",
       "82323                                          [Chablis]   \n",
       "82324  [1 Lithium carbonate 150 mg capsules. Lithium ...   \n",
       "82325  [Burdick & Jackson solvents are arranged in or...   \n",
       "\n",
       "                                                passages  \\\n",
       "0      {'is_selected': [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]...   \n",
       "1      {'is_selected': [0, 1, 0, 0, 0, 0, 0], 'passag...   \n",
       "2      {'is_selected': [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]...   \n",
       "3      {'is_selected': [0, 0, 0, 0, 0, 0, 0, 0, 1], '...   \n",
       "4      {'is_selected': [0, 0, 1, 0, 0, 0, 0, 0], 'pas...   \n",
       "...                                                  ...   \n",
       "82321  {'is_selected': [1, 0, 0], 'passage_text': ['d...   \n",
       "82322  {'is_selected': [0, 0, 1, 0, 0, 0, 0, 0, 0], '...   \n",
       "82323  {'is_selected': [0, 1, 0, 0, 0, 0], 'passage_t...   \n",
       "82324  {'is_selected': [0, 0, 0, 1, 0, 0, 0, 0, 0], '...   \n",
       "82325  {'is_selected': [1, 0, 0, 0, 0, 0, 0, 0, 0, 0]...   \n",
       "\n",
       "                                                   query  query_id  \\\n",
       "0                                            what is rba     19699   \n",
       "1                           was ronald reagan a democrat     19700   \n",
       "2      how long do you need for sydney and surroundin...     19701   \n",
       "3                        price to install tile in shower     19702   \n",
       "4                        why conversion observed in body     19703   \n",
       "...                                                  ...       ...   \n",
       "82321                             meaning of propagation    102124   \n",
       "82322  do you have to do a phd to be a clinical psych...    102125   \n",
       "82323                        what wine goes with oysters    102126   \n",
       "82324                what strengths does lithium come in    102127   \n",
       "82325                  what is polarity index definition    102128   \n",
       "\n",
       "        query_type wellFormedAnswers  \n",
       "0      description                []  \n",
       "1      description                []  \n",
       "2          numeric                []  \n",
       "3          numeric                []  \n",
       "4      description                []  \n",
       "...            ...               ...  \n",
       "82321  description                []  \n",
       "82322  description                []  \n",
       "82323       entity                []  \n",
       "82324  description                []  \n",
       "82325  description                []  \n",
       "\n",
       "[82326 rows x 6 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0837007d-9faf-443f-93e0-f7128e393243",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create column to store all the passages text\n",
    "train_df[\"clean_text\"] = train_df.loc[:,\"passages\"].apply(lambda x: x['passage_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b3d60f5a-7528-4829-bd39-6e9ea93ec71d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a columns to store the passage indexes, in order to later be able to access the indexes.\n",
    "val= 0\n",
    "all_indexes = []\n",
    "for line in train_df.clean_text:\n",
    "    indexes = []\n",
    "    for element in line: \n",
    "        val +=1\n",
    "        indexes.append(val)\n",
    "    \n",
    "    all_indexes.append(indexes) \n",
    "train_df[\"indexes\"] = all_indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9b9ccf7e-2e98-4171-aaa8-421280195762",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>answers</th>\n",
       "      <th>passages</th>\n",
       "      <th>query</th>\n",
       "      <th>query_id</th>\n",
       "      <th>query_type</th>\n",
       "      <th>wellFormedAnswers</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>indexes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[Results-Based Accountability is a disciplined...</td>\n",
       "      <td>{'is_selected': [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]...</td>\n",
       "      <td>what is rba</td>\n",
       "      <td>19699</td>\n",
       "      <td>description</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Since 2007, the RBA's outstanding reputation ...</td>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[Yes]</td>\n",
       "      <td>{'is_selected': [0, 1, 0, 0, 0, 0, 0], 'passag...</td>\n",
       "      <td>was ronald reagan a democrat</td>\n",
       "      <td>19700</td>\n",
       "      <td>description</td>\n",
       "      <td>[]</td>\n",
       "      <td>[In his younger years, Ronald Reagan was a mem...</td>\n",
       "      <td>[11, 12, 13, 14, 15, 16, 17]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[20-25 minutes]</td>\n",
       "      <td>{'is_selected': [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]...</td>\n",
       "      <td>how long do you need for sydney and surroundin...</td>\n",
       "      <td>19701</td>\n",
       "      <td>numeric</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Sydney, New South Wales, Australia is located...</td>\n",
       "      <td>[18, 19, 20, 21, 22, 23, 24, 25, 26, 27]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[$11 to $22 per square foot]</td>\n",
       "      <td>{'is_selected': [0, 0, 0, 0, 0, 0, 0, 0, 1], '...</td>\n",
       "      <td>price to install tile in shower</td>\n",
       "      <td>19702</td>\n",
       "      <td>numeric</td>\n",
       "      <td>[]</td>\n",
       "      <td>[In regards to tile installation costs, consum...</td>\n",
       "      <td>[28, 29, 30, 31, 32, 33, 34, 35, 36]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[Due to symptoms in the body]</td>\n",
       "      <td>{'is_selected': [0, 0, 1, 0, 0, 0, 0, 0], 'pas...</td>\n",
       "      <td>why conversion observed in body</td>\n",
       "      <td>19703</td>\n",
       "      <td>description</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Conclusions: In adult body CT, dose to an org...</td>\n",
       "      <td>[37, 38, 39, 40, 41, 42, 43, 44]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             answers  \\\n",
       "0  [Results-Based Accountability is a disciplined...   \n",
       "1                                              [Yes]   \n",
       "2                                    [20-25 minutes]   \n",
       "3                       [$11 to $22 per square foot]   \n",
       "4                      [Due to symptoms in the body]   \n",
       "\n",
       "                                            passages  \\\n",
       "0  {'is_selected': [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]...   \n",
       "1  {'is_selected': [0, 1, 0, 0, 0, 0, 0], 'passag...   \n",
       "2  {'is_selected': [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]...   \n",
       "3  {'is_selected': [0, 0, 0, 0, 0, 0, 0, 0, 1], '...   \n",
       "4  {'is_selected': [0, 0, 1, 0, 0, 0, 0, 0], 'pas...   \n",
       "\n",
       "                                               query  query_id   query_type  \\\n",
       "0                                        what is rba     19699  description   \n",
       "1                       was ronald reagan a democrat     19700  description   \n",
       "2  how long do you need for sydney and surroundin...     19701      numeric   \n",
       "3                    price to install tile in shower     19702      numeric   \n",
       "4                    why conversion observed in body     19703  description   \n",
       "\n",
       "  wellFormedAnswers                                         clean_text  \\\n",
       "0                []  [Since 2007, the RBA's outstanding reputation ...   \n",
       "1                []  [In his younger years, Ronald Reagan was a mem...   \n",
       "2                []  [Sydney, New South Wales, Australia is located...   \n",
       "3                []  [In regards to tile installation costs, consum...   \n",
       "4                []  [Conclusions: In adult body CT, dose to an org...   \n",
       "\n",
       "                                    indexes  \n",
       "0           [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]  \n",
       "1              [11, 12, 13, 14, 15, 16, 17]  \n",
       "2  [18, 19, 20, 21, 22, 23, 24, 25, 26, 27]  \n",
       "3      [28, 29, 30, 31, 32, 33, 34, 35, 36]  \n",
       "4          [37, 38, 39, 40, 41, 42, 43, 44]  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5159dff-3728-4417-b361-9102560c7ee9",
   "metadata": {},
   "source": [
    "# Let's compute baseline using available lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4df5ad56-5d9f-45d2-9787-a4d387052176",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rank_bm25 import BM25Okapi\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d31bd8f6-ea19-4fbf-ad4c-7e9dee30bfe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = []\n",
    "for line in train_df.clean_text:\n",
    "    document = []\n",
    "    for i in line:\n",
    "        document.append(word_tokenize(i.lower()))\n",
    "    corpus += document\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ded42a6f-b0af-4d02-bf78-cdbda5323067",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's build the index \n",
    "bm25_title = BM25Okapi(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d8c2543f-dd6a-4ad5-a1c9-cebfebe87f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"word_tokenize\"] = train_df[\"query\"].apply(word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fe60dffb-d362-4d5e-9082-701bce0dbc3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_top_n_indices(scores, n=10):\n",
    "    \"\"\" Return top n results given a list of scores \"\"\"\n",
    "    # Create a list of (index, value) pairs\n",
    "    indexed_list = list(enumerate(scores))\n",
    "    \n",
    "    # Sort the indexed list by value in descending order\n",
    "    indexed_list.sort(key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # Get the indices of the top 10 values\n",
    "    top_10_indices = [index for index, _ in indexed_list[:n]]\n",
    "    return top_10_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ed6329-23f5-49d1-b023-215f23321597",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "08fdd0b6-d6c7-480d-abda-f21c7d44b64d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [01:43<00:00,  1.03s/it]\n"
     ]
    }
   ],
   "source": [
    "result = []\n",
    "import tqdm\n",
    "for row in tqdm.tqdm(train_df[\"word_tokenize\"][:100]):  # run just for 100 queries due to slow predict time\n",
    "    value = bm25_title.get_scores(row)\n",
    "    #value = bm25_title.get_top_n(row, corpus, n=10)\n",
    "    result.append(return_top_n_indices(value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6ad90967-fc4c-4628-bbd8-345f1edbf2d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure we have the same length\n",
    "train_df = train_df[:len(result)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "43912838-bc33-4d7d-8cad-5c0452e09af6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qm/9nf5psg15297qj1c3tsnyhk00000gq/T/ipykernel_14477/349395212.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_df[\"retriever\"] = result\n"
     ]
    }
   ],
   "source": [
    "# Saves result indexes\n",
    "train_df[\"retriever\"] = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b218e955-bcc2-4484-b126-f455b9e721e6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>answers</th>\n",
       "      <th>passages</th>\n",
       "      <th>query</th>\n",
       "      <th>query_id</th>\n",
       "      <th>query_type</th>\n",
       "      <th>wellFormedAnswers</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>indexes</th>\n",
       "      <th>word_tokenize</th>\n",
       "      <th>retriever</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[Results-Based Accountability is a disciplined...</td>\n",
       "      <td>{'is_selected': [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]...</td>\n",
       "      <td>what is rba</td>\n",
       "      <td>19699</td>\n",
       "      <td>description</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Since 2007, the RBA's outstanding reputation ...</td>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]</td>\n",
       "      <td>[what, is, rba]</td>\n",
       "      <td>[333792, 333789, 8, 3, 4, 5, 6, 0, 7, 137248]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[Yes]</td>\n",
       "      <td>{'is_selected': [0, 1, 0, 0, 0, 0, 0], 'passag...</td>\n",
       "      <td>was ronald reagan a democrat</td>\n",
       "      <td>19700</td>\n",
       "      <td>description</td>\n",
       "      <td>[]</td>\n",
       "      <td>[In his younger years, Ronald Reagan was a mem...</td>\n",
       "      <td>[11, 12, 13, 14, 15, 16, 17]</td>\n",
       "      <td>[was, ronald, reagan, a, democrat]</td>\n",
       "      <td>[14, 11, 391341, 624933, 624926, 344774, 24594...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[20-25 minutes]</td>\n",
       "      <td>{'is_selected': [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]...</td>\n",
       "      <td>how long do you need for sydney and surroundin...</td>\n",
       "      <td>19701</td>\n",
       "      <td>numeric</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Sydney, New South Wales, Australia is located...</td>\n",
       "      <td>[18, 19, 20, 21, 22, 23, 24, 25, 26, 27]</td>\n",
       "      <td>[how, long, do, you, need, for, sydney, and, s...</td>\n",
       "      <td>[25, 19, 63938, 559080, 63937, 101552, 556007,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[$11 to $22 per square foot]</td>\n",
       "      <td>{'is_selected': [0, 0, 0, 0, 0, 0, 0, 0, 1], '...</td>\n",
       "      <td>price to install tile in shower</td>\n",
       "      <td>19702</td>\n",
       "      <td>numeric</td>\n",
       "      <td>[]</td>\n",
       "      <td>[In regards to tile installation costs, consum...</td>\n",
       "      <td>[28, 29, 30, 31, 32, 33, 34, 35, 36]</td>\n",
       "      <td>[price, to, install, tile, in, shower]</td>\n",
       "      <td>[341394, 491520, 462958, 596050, 259278, 51876...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[Due to symptoms in the body]</td>\n",
       "      <td>{'is_selected': [0, 0, 1, 0, 0, 0, 0, 0], 'pas...</td>\n",
       "      <td>why conversion observed in body</td>\n",
       "      <td>19703</td>\n",
       "      <td>description</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Conclusions: In adult body CT, dose to an org...</td>\n",
       "      <td>[37, 38, 39, 40, 41, 42, 43, 44]</td>\n",
       "      <td>[why, conversion, observed, in, body]</td>\n",
       "      <td>[479697, 652251, 529330, 18139, 594514, 508156...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>[WatchDog.sys is a vital system file used by t...</td>\n",
       "      <td>{'is_selected': [0, 0, 0, 0, 1, 0, 0, 0, 0], '...</td>\n",
       "      <td>watchdog.sys what is</td>\n",
       "      <td>19794</td>\n",
       "      <td>description</td>\n",
       "      <td>[]</td>\n",
       "      <td>[WatchDog.sys was originally stored in the sys...</td>\n",
       "      <td>[775, 776, 777, 778, 779, 780, 781, 782, 783]</td>\n",
       "      <td>[watchdog.sys, what, is]</td>\n",
       "      <td>[775, 779, 782, 777, 778, 776, 774, 781, 62692...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>[In computing, .bak is a filename extension co...</td>\n",
       "      <td>{'is_selected': [0, 0, 0, 0, 0, 0, 0, 1], 'pas...</td>\n",
       "      <td>what is a bak file</td>\n",
       "      <td>19795</td>\n",
       "      <td>description</td>\n",
       "      <td>[]</td>\n",
       "      <td>[The easiest way to open a BAK file is to doub...</td>\n",
       "      <td>[784, 785, 786, 787, 788, 789, 790, 791]</td>\n",
       "      <td>[what, is, a, bak, file]</td>\n",
       "      <td>[785, 783, 789, 787, 784, 597850, 554742, 1999...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>[Public, four-year colleges cost $7,000 for in...</td>\n",
       "      <td>{'is_selected': [0, 0, 0, 0, 0, 0, 1, 0, 0], '...</td>\n",
       "      <td>How much will it cost to go to college to beco...</td>\n",
       "      <td>19796</td>\n",
       "      <td>numeric</td>\n",
       "      <td>[]</td>\n",
       "      <td>[A: The degree that you need to be a detective...</td>\n",
       "      <td>[792, 793, 794, 795, 796, 797, 798, 799, 800]</td>\n",
       "      <td>[How, much, will, it, cost, to, go, to, colleg...</td>\n",
       "      <td>[442170, 791, 92803, 577458, 15476, 261638, 79...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>[A document used to change one or more minor p...</td>\n",
       "      <td>{'is_selected': [0, 0, 0, 1, 0, 1, 0, 0, 0], '...</td>\n",
       "      <td>trust amendment term</td>\n",
       "      <td>19797</td>\n",
       "      <td>description</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Trust Restatement Law &amp; Legal Definition. A r...</td>\n",
       "      <td>[801, 802, 803, 804, 805, 806, 807, 808, 809]</td>\n",
       "      <td>[trust, amendment, term]</td>\n",
       "      <td>[805, 807, 803, 802, 537989, 800, 804, 441656,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>[Kuchen means cake in German, and refers to a ...</td>\n",
       "      <td>{'is_selected': [0, 0, 0, 1, 0], 'passage_text...</td>\n",
       "      <td>what is kuchen</td>\n",
       "      <td>19798</td>\n",
       "      <td>description</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Some Kuchen's use just a Streusal topping, wh...</td>\n",
       "      <td>[810, 811, 812, 813, 814]</td>\n",
       "      <td>[what, is, kuchen]</td>\n",
       "      <td>[813, 809, 811, 812, 810, 626922, 508435, 6269...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              answers  \\\n",
       "0   [Results-Based Accountability is a disciplined...   \n",
       "1                                               [Yes]   \n",
       "2                                     [20-25 minutes]   \n",
       "3                        [$11 to $22 per square foot]   \n",
       "4                       [Due to symptoms in the body]   \n",
       "..                                                ...   \n",
       "95  [WatchDog.sys is a vital system file used by t...   \n",
       "96  [In computing, .bak is a filename extension co...   \n",
       "97  [Public, four-year colleges cost $7,000 for in...   \n",
       "98  [A document used to change one or more minor p...   \n",
       "99  [Kuchen means cake in German, and refers to a ...   \n",
       "\n",
       "                                             passages  \\\n",
       "0   {'is_selected': [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]...   \n",
       "1   {'is_selected': [0, 1, 0, 0, 0, 0, 0], 'passag...   \n",
       "2   {'is_selected': [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]...   \n",
       "3   {'is_selected': [0, 0, 0, 0, 0, 0, 0, 0, 1], '...   \n",
       "4   {'is_selected': [0, 0, 1, 0, 0, 0, 0, 0], 'pas...   \n",
       "..                                                ...   \n",
       "95  {'is_selected': [0, 0, 0, 0, 1, 0, 0, 0, 0], '...   \n",
       "96  {'is_selected': [0, 0, 0, 0, 0, 0, 0, 1], 'pas...   \n",
       "97  {'is_selected': [0, 0, 0, 0, 0, 0, 1, 0, 0], '...   \n",
       "98  {'is_selected': [0, 0, 0, 1, 0, 1, 0, 0, 0], '...   \n",
       "99  {'is_selected': [0, 0, 0, 1, 0], 'passage_text...   \n",
       "\n",
       "                                                query  query_id   query_type  \\\n",
       "0                                         what is rba     19699  description   \n",
       "1                        was ronald reagan a democrat     19700  description   \n",
       "2   how long do you need for sydney and surroundin...     19701      numeric   \n",
       "3                     price to install tile in shower     19702      numeric   \n",
       "4                     why conversion observed in body     19703  description   \n",
       "..                                                ...       ...          ...   \n",
       "95                               watchdog.sys what is     19794  description   \n",
       "96                                 what is a bak file     19795  description   \n",
       "97  How much will it cost to go to college to beco...     19796      numeric   \n",
       "98                               trust amendment term     19797  description   \n",
       "99                                     what is kuchen     19798  description   \n",
       "\n",
       "   wellFormedAnswers                                         clean_text  \\\n",
       "0                 []  [Since 2007, the RBA's outstanding reputation ...   \n",
       "1                 []  [In his younger years, Ronald Reagan was a mem...   \n",
       "2                 []  [Sydney, New South Wales, Australia is located...   \n",
       "3                 []  [In regards to tile installation costs, consum...   \n",
       "4                 []  [Conclusions: In adult body CT, dose to an org...   \n",
       "..               ...                                                ...   \n",
       "95                []  [WatchDog.sys was originally stored in the sys...   \n",
       "96                []  [The easiest way to open a BAK file is to doub...   \n",
       "97                []  [A: The degree that you need to be a detective...   \n",
       "98                []  [Trust Restatement Law & Legal Definition. A r...   \n",
       "99                []  [Some Kuchen's use just a Streusal topping, wh...   \n",
       "\n",
       "                                          indexes  \\\n",
       "0                 [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]   \n",
       "1                    [11, 12, 13, 14, 15, 16, 17]   \n",
       "2        [18, 19, 20, 21, 22, 23, 24, 25, 26, 27]   \n",
       "3            [28, 29, 30, 31, 32, 33, 34, 35, 36]   \n",
       "4                [37, 38, 39, 40, 41, 42, 43, 44]   \n",
       "..                                            ...   \n",
       "95  [775, 776, 777, 778, 779, 780, 781, 782, 783]   \n",
       "96       [784, 785, 786, 787, 788, 789, 790, 791]   \n",
       "97  [792, 793, 794, 795, 796, 797, 798, 799, 800]   \n",
       "98  [801, 802, 803, 804, 805, 806, 807, 808, 809]   \n",
       "99                      [810, 811, 812, 813, 814]   \n",
       "\n",
       "                                        word_tokenize  \\\n",
       "0                                     [what, is, rba]   \n",
       "1                  [was, ronald, reagan, a, democrat]   \n",
       "2   [how, long, do, you, need, for, sydney, and, s...   \n",
       "3              [price, to, install, tile, in, shower]   \n",
       "4               [why, conversion, observed, in, body]   \n",
       "..                                                ...   \n",
       "95                           [watchdog.sys, what, is]   \n",
       "96                           [what, is, a, bak, file]   \n",
       "97  [How, much, will, it, cost, to, go, to, colleg...   \n",
       "98                           [trust, amendment, term]   \n",
       "99                                 [what, is, kuchen]   \n",
       "\n",
       "                                            retriever  \n",
       "0       [333792, 333789, 8, 3, 4, 5, 6, 0, 7, 137248]  \n",
       "1   [14, 11, 391341, 624933, 624926, 344774, 24594...  \n",
       "2   [25, 19, 63938, 559080, 63937, 101552, 556007,...  \n",
       "3   [341394, 491520, 462958, 596050, 259278, 51876...  \n",
       "4   [479697, 652251, 529330, 18139, 594514, 508156...  \n",
       "..                                                ...  \n",
       "95  [775, 779, 782, 777, 778, 776, 774, 781, 62692...  \n",
       "96  [785, 783, 789, 787, 784, 597850, 554742, 1999...  \n",
       "97  [442170, 791, 92803, 577458, 15476, 261638, 79...  \n",
       "98  [805, 807, 803, 802, 537989, 800, 804, 441656,...  \n",
       "99  [813, 809, 811, 812, 810, 626922, 508435, 6269...  \n",
       "\n",
       "[100 rows x 10 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cc651be7-743b-4b22-b523-dd5011b6fd53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def precisioK(ground_truth, retrieved_items):\n",
    "    # Calculate the number of common elements between the two lists\n",
    "    common_elements = set(ground_truth) & set(retrieved_items)\n",
    "    \n",
    "    # Compute precision\n",
    "    precision = len(common_elements) / len(ground_truth)\n",
    "    return precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "932cd9fe-b535-4f15-9a02-711b146dfb6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = train_df.apply(lambda row: precisioK(row['indexes'], row['retriever']), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "609a0966-7596-4542-a7d8-e4c50617bead",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.30794444444444447"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01124377-97ea-435d-9b14-4ae317739289",
   "metadata": {},
   "source": [
    "# Run beir benchmark\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e4275566-7f53-4058-9ee3-509eeb9b52b5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://__token__:****@git.naspersclassifieds.com/api/v4/projects/35468/packages/pypi/simple\n",
      "Requirement already satisfied: beir in /Users/tiago.cabo/Documents/github-repos/moviellens-ai-playground/.venv/lib/python3.11/site-packages (2.0.0)\n",
      "Requirement already satisfied: sentence-transformers in /Users/tiago.cabo/Documents/github-repos/moviellens-ai-playground/.venv/lib/python3.11/site-packages (from beir) (2.2.2)\n",
      "Requirement already satisfied: pytrec-eval in /Users/tiago.cabo/Documents/github-repos/moviellens-ai-playground/.venv/lib/python3.11/site-packages (from beir) (0.5)\n",
      "Requirement already satisfied: faiss-cpu in /Users/tiago.cabo/Documents/github-repos/moviellens-ai-playground/.venv/lib/python3.11/site-packages (from beir) (1.7.4)\n",
      "Requirement already satisfied: elasticsearch==7.9.1 in /Users/tiago.cabo/Documents/github-repos/moviellens-ai-playground/.venv/lib/python3.11/site-packages (from beir) (7.9.1)\n",
      "Requirement already satisfied: datasets in /Users/tiago.cabo/Documents/github-repos/moviellens-ai-playground/.venv/lib/python3.11/site-packages (from beir) (2.14.5)\n",
      "Requirement already satisfied: urllib3>=1.21.1 in /Users/tiago.cabo/Documents/github-repos/moviellens-ai-playground/.venv/lib/python3.11/site-packages (from elasticsearch==7.9.1->beir) (2.0.6)\n",
      "Requirement already satisfied: certifi in /Users/tiago.cabo/Documents/github-repos/moviellens-ai-playground/.venv/lib/python3.11/site-packages (from elasticsearch==7.9.1->beir) (2023.7.22)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/tiago.cabo/Documents/github-repos/moviellens-ai-playground/.venv/lib/python3.11/site-packages (from datasets->beir) (1.26.2)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /Users/tiago.cabo/Documents/github-repos/moviellens-ai-playground/.venv/lib/python3.11/site-packages (from datasets->beir) (13.0.0)\n",
      "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /Users/tiago.cabo/Documents/github-repos/moviellens-ai-playground/.venv/lib/python3.11/site-packages (from datasets->beir) (0.3.7)\n",
      "Requirement already satisfied: pandas in /Users/tiago.cabo/Documents/github-repos/moviellens-ai-playground/.venv/lib/python3.11/site-packages (from datasets->beir) (2.1.1)\n",
      "Requirement already satisfied: requests>=2.19.0 in /Users/tiago.cabo/Documents/github-repos/moviellens-ai-playground/.venv/lib/python3.11/site-packages (from datasets->beir) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /Users/tiago.cabo/Documents/github-repos/moviellens-ai-playground/.venv/lib/python3.11/site-packages (from datasets->beir) (4.66.1)\n",
      "Requirement already satisfied: xxhash in /Users/tiago.cabo/Documents/github-repos/moviellens-ai-playground/.venv/lib/python3.11/site-packages (from datasets->beir) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /Users/tiago.cabo/Documents/github-repos/moviellens-ai-playground/.venv/lib/python3.11/site-packages (from datasets->beir) (0.70.15)\n",
      "Requirement already satisfied: fsspec[http]<2023.9.0,>=2023.1.0 in /Users/tiago.cabo/Documents/github-repos/moviellens-ai-playground/.venv/lib/python3.11/site-packages (from datasets->beir) (2023.6.0)\n",
      "Requirement already satisfied: aiohttp in /Users/tiago.cabo/Documents/github-repos/moviellens-ai-playground/.venv/lib/python3.11/site-packages (from datasets->beir) (3.8.6)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.14.0 in /Users/tiago.cabo/Documents/github-repos/moviellens-ai-playground/.venv/lib/python3.11/site-packages (from datasets->beir) (0.18.0)\n",
      "Requirement already satisfied: packaging in /Users/tiago.cabo/Documents/github-repos/moviellens-ai-playground/.venv/lib/python3.11/site-packages (from datasets->beir) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/tiago.cabo/Documents/github-repos/moviellens-ai-playground/.venv/lib/python3.11/site-packages (from datasets->beir) (6.0.1)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in /Users/tiago.cabo/Documents/github-repos/moviellens-ai-playground/.venv/lib/python3.11/site-packages (from sentence-transformers->beir) (4.33.1)\n",
      "Requirement already satisfied: torch>=1.6.0 in /Users/tiago.cabo/Documents/github-repos/moviellens-ai-playground/.venv/lib/python3.11/site-packages (from sentence-transformers->beir) (2.0.1)\n",
      "Requirement already satisfied: torchvision in /Users/tiago.cabo/Documents/github-repos/moviellens-ai-playground/.venv/lib/python3.11/site-packages (from sentence-transformers->beir) (0.15.2)\n",
      "Requirement already satisfied: scikit-learn in /Users/tiago.cabo/Documents/github-repos/moviellens-ai-playground/.venv/lib/python3.11/site-packages (from sentence-transformers->beir) (1.3.0)\n",
      "Requirement already satisfied: scipy in /Users/tiago.cabo/Documents/github-repos/moviellens-ai-playground/.venv/lib/python3.11/site-packages (from sentence-transformers->beir) (1.11.4)\n",
      "Requirement already satisfied: nltk in /Users/tiago.cabo/Documents/github-repos/moviellens-ai-playground/.venv/lib/python3.11/site-packages (from sentence-transformers->beir) (3.8.1)\n",
      "Requirement already satisfied: sentencepiece in /Users/tiago.cabo/Documents/github-repos/moviellens-ai-playground/.venv/lib/python3.11/site-packages (from sentence-transformers->beir) (0.1.99)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/tiago.cabo/Documents/github-repos/moviellens-ai-playground/.venv/lib/python3.11/site-packages (from aiohttp->datasets->beir) (23.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /Users/tiago.cabo/Documents/github-repos/moviellens-ai-playground/.venv/lib/python3.11/site-packages (from aiohttp->datasets->beir) (3.3.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/tiago.cabo/Documents/github-repos/moviellens-ai-playground/.venv/lib/python3.11/site-packages (from aiohttp->datasets->beir) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /Users/tiago.cabo/Documents/github-repos/moviellens-ai-playground/.venv/lib/python3.11/site-packages (from aiohttp->datasets->beir) (4.0.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/tiago.cabo/Documents/github-repos/moviellens-ai-playground/.venv/lib/python3.11/site-packages (from aiohttp->datasets->beir) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/tiago.cabo/Documents/github-repos/moviellens-ai-playground/.venv/lib/python3.11/site-packages (from aiohttp->datasets->beir) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/tiago.cabo/Documents/github-repos/moviellens-ai-playground/.venv/lib/python3.11/site-packages (from aiohttp->datasets->beir) (1.3.1)\n",
      "Requirement already satisfied: filelock in /Users/tiago.cabo/Documents/github-repos/moviellens-ai-playground/.venv/lib/python3.11/site-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets->beir) (3.12.4)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/tiago.cabo/Documents/github-repos/moviellens-ai-playground/.venv/lib/python3.11/site-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets->beir) (4.8.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/tiago.cabo/Documents/github-repos/moviellens-ai-playground/.venv/lib/python3.11/site-packages (from requests>=2.19.0->datasets->beir) (3.4)\n",
      "Requirement already satisfied: sympy in /Users/tiago.cabo/Documents/github-repos/moviellens-ai-playground/.venv/lib/python3.11/site-packages (from torch>=1.6.0->sentence-transformers->beir) (1.12)\n",
      "Requirement already satisfied: networkx in /Users/tiago.cabo/Documents/github-repos/moviellens-ai-playground/.venv/lib/python3.11/site-packages (from torch>=1.6.0->sentence-transformers->beir) (3.1)\n",
      "Requirement already satisfied: jinja2 in /Users/tiago.cabo/Documents/github-repos/moviellens-ai-playground/.venv/lib/python3.11/site-packages (from torch>=1.6.0->sentence-transformers->beir) (3.1.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/tiago.cabo/Documents/github-repos/moviellens-ai-playground/.venv/lib/python3.11/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers->beir) (2023.8.8)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /Users/tiago.cabo/Documents/github-repos/moviellens-ai-playground/.venv/lib/python3.11/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers->beir) (0.13.3)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /Users/tiago.cabo/Documents/github-repos/moviellens-ai-playground/.venv/lib/python3.11/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers->beir) (0.3.3)\n",
      "Requirement already satisfied: click in /Users/tiago.cabo/Documents/github-repos/moviellens-ai-playground/.venv/lib/python3.11/site-packages (from nltk->sentence-transformers->beir) (8.1.7)\n",
      "Requirement already satisfied: joblib in /Users/tiago.cabo/Documents/github-repos/moviellens-ai-playground/.venv/lib/python3.11/site-packages (from nltk->sentence-transformers->beir) (1.3.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/tiago.cabo/Documents/github-repos/moviellens-ai-playground/.venv/lib/python3.11/site-packages (from pandas->datasets->beir) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/tiago.cabo/Documents/github-repos/moviellens-ai-playground/.venv/lib/python3.11/site-packages (from pandas->datasets->beir) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Users/tiago.cabo/Documents/github-repos/moviellens-ai-playground/.venv/lib/python3.11/site-packages (from pandas->datasets->beir) (2023.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/tiago.cabo/Documents/github-repos/moviellens-ai-playground/.venv/lib/python3.11/site-packages (from scikit-learn->sentence-transformers->beir) (3.2.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /Users/tiago.cabo/Documents/github-repos/moviellens-ai-playground/.venv/lib/python3.11/site-packages (from torchvision->sentence-transformers->beir) (9.5.0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/tiago.cabo/Documents/github-repos/moviellens-ai-playground/.venv/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->datasets->beir) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/tiago.cabo/Documents/github-repos/moviellens-ai-playground/.venv/lib/python3.11/site-packages (from jinja2->torch>=1.6.0->sentence-transformers->beir) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/tiago.cabo/Documents/github-repos/moviellens-ai-playground/.venv/lib/python3.11/site-packages (from sympy->torch>=1.6.0->sentence-transformers->beir) (1.3.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install beir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2196a1af-8ff8-4022-91dc-dfcd127b75f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from beir import util, LoggingHandler\n",
    "\n",
    "import logging\n",
    "import pathlib, os\n",
    "\n",
    "#### Just some code to print debug information to stdout\n",
    "logging.basicConfig(format='%(asctime)s - %(message)s',\n",
    "                    datefmt='%Y-%m-%d %H:%M:%S',\n",
    "                    level=logging.INFO,\n",
    "                    handlers=[LoggingHandler()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6bf01603-8ab2-4e3b-b488-6db670a29cdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset downloaded here: /Users/tiago.cabo/Documents/github-repos/moviellens-ai-playground/notebooks/datasets/msmarco\n"
     ]
    }
   ],
   "source": [
    "import pathlib, os\n",
    "from beir import util\n",
    "\n",
    "dataset = \"msmarco\"\n",
    "url = \"https://public.ukp.informatik.tu-darmstadt.de/thakur/BEIR/datasets/{}.zip\".format(dataset)\n",
    "out_dir = os.path.join(os.getcwd(), \"datasets\")\n",
    "data_path = util.download_and_unzip(url, out_dir)\n",
    "print(\"Dataset downloaded here: {}\".format(data_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "773e6274-553d-4073-9d16-bf01b8c7db4a",
   "metadata": {},
   "source": [
    "Folder Structure of any BEIR dataset:\n",
    "- scifact/\n",
    "    -    corpus.jsonl\n",
    "    -    queries.jsonl\n",
    "    -    qrels/\n",
    "    -    train.tsv\n",
    "    -    dev.tsv\n",
    "    -    test.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ea004311-c0ce-469c-9662-3cb0f6e09d4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-03 19:40:03 - Loading Corpus...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ee7371ec527401390b4c7652905b703",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8841823 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-03 19:40:25 - Loaded 8841823 TEST Documents.\n",
      "2023-12-03 19:40:26 - Doc Example: {'text': 'The presence of communication amid scientific minds was equally important to the success of the Manhattan Project as scientific intellect was. The only cloud hanging over the impressive achievement of the atomic researchers and engineers is what their success truly meant; hundreds of thousands of innocent lives obliterated.', 'title': ''}\n",
      "2023-12-03 19:40:26 - Loading Queries...\n",
      "2023-12-03 19:40:26 - Loaded 43 TEST Queries.\n",
      "2023-12-03 19:40:26 - Query Example: anthropological definition of environment\n"
     ]
    }
   ],
   "source": [
    "# **Data Loading**\n",
    "\n",
    "from beir.datasets.data_loader import GenericDataLoader\n",
    "\n",
    "data_path = \"datasets/msmarco\"\n",
    "corpus, queries, qrels = GenericDataLoader(data_path).load(split=\"test\") # or split = \"train\" or \"dev\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2679f3cc-be7d-41ea-8273-7ae0347ab350",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limit data to sped up\n",
    "corpus = dict(list(corpus.items())[:500000])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c43e180a-641d-466a-8ede-732586e75f3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(qrels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1342c148-7a81-4b9e-a92d-08bcb0b39865",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 500000/500000 [00:01<00:00, 290282.86it/s]\n"
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "# case you need to sped up, please reduce the data\n",
    "tokenized_corpus = [doc['text'].split(\" \") for doc in tqdm.tqdm(corpus.values())]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "126087d2-e4b2-4c3f-b66a-87b96f91fbd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# indexing\n",
    "bm25 = BM25Okapi(tokenized_corpus)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7486d37e-2e48-4e19-9c8d-9b6d5997f2ed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(qrels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "23980b66-ef5b-412e-afe3-af765865f306",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 43/43 [00:22<00:00,  1.91it/s]\n"
     ]
    }
   ],
   "source": [
    "# Retrieval with BM25\n",
    "results = {}\n",
    "for query_id, query in tqdm.tqdm(queries.items()):\n",
    "    scores = bm25.get_scores(queries[query_id].split(\" \"))\n",
    "    results[query_id] = {doc_id: score for doc_id, score in zip(corpus.keys(), scores)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7e304e89-b4e8-43f7-8e6e-292a958c25d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "41d01f17-c256-4474-b99b-846ccbc10eb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-03 19:41:13 - For evaluation, we ignore identical query and document ids (default), please explicitly set ``ignore_identical_ids=False`` to ignore this.\n",
      "2023-12-03 19:41:24 - \n",
      "\n",
      "2023-12-03 19:41:24 - NDCG@5: 0.1647\n",
      "2023-12-03 19:41:24 - NDCG@10: 0.1323\n",
      "2023-12-03 19:41:24 - \n",
      "\n",
      "2023-12-03 19:41:24 - MAP@5: 0.0121\n",
      "2023-12-03 19:41:24 - MAP@10: 0.0165\n",
      "2023-12-03 19:41:24 - \n",
      "\n",
      "2023-12-03 19:41:24 - Recall@5: 0.0142\n",
      "2023-12-03 19:41:24 - Recall@10: 0.0200\n",
      "2023-12-03 19:41:24 - \n",
      "\n",
      "2023-12-03 19:41:24 - P@5: 0.2233\n",
      "2023-12-03 19:41:24 - P@10: 0.1605\n"
     ]
    }
   ],
   "source": [
    "from beir.retrieval.evaluation import EvaluateRetrieval\n",
    "\n",
    "# Evaluate\n",
    "evaluator = EvaluateRetrieval()\n",
    "ndcg, _map, recall, precision = evaluator.evaluate(qrels, results, k_values=[5,10])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
